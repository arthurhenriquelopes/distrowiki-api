# MÃ³dulo de Scraping - DistroWatch

MÃ³dulo modular para scraping de distribuiÃ§Ãµes Linux do DistroWatch usando proxies rotativos.

## ğŸ“‹ CaracterÃ­sticas

- âœ… **RotaÃ§Ã£o de Proxies**: Sistema automÃ¡tico de rotaÃ§Ã£o de proxies para evitar IP ban
- âœ… **Rate Limiting**: Delays inteligentes entre requisiÃ§Ãµes
- âœ… **Retry AutomÃ¡tico**: Fallback e retry em caso de falhas
- âœ… **Background Tasks**: Scraping executado em background via FastAPI
- âœ… **Monitoramento**: Endpoints para monitorar progresso e status
- âœ… **Modular**: Pode ser facilmente removido sem afetar o resto da API

## ğŸš€ Como Usar

### 1. Instalar DependÃªncias

```bash
pip install beautifulsoup4 requests lxml
```

Ou usando o requirements.txt do mÃ³dulo:

```bash
pip install -r api/scraping/requirements.txt
```

### 2. Adicionar Proxies

```bash
curl -X POST "http://localhost:8000/scraping/proxies" \
  -H "Content-Type: application/json" \
  -d '{
    "proxy_urls": [
      "http://proxy1.example.com:8080",
      "http://proxy2.example.com:8080"
    ]
  }'
```

### 3. Validar Proxies

```bash
curl -X POST "http://localhost:8000/scraping/proxies/validate"
```

### 4. Iniciar Scraping

```bash
curl -X POST "http://localhost:8000/scraping/start" \
  -H "Content-Type: application/json" \
  -d '{
    "limit": 10,
    "use_proxies": true
  }'
```

### 5. Monitorar Progresso

```bash
curl "http://localhost:8000/scraping/status"
```

### 6. Obter Resultados

```bash
curl "http://localhost:8000/scraping/results"
```

## ğŸ“¡ Endpoints

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| GET | `/scraping/` | InformaÃ§Ãµes do mÃ³dulo |
| GET | `/scraping/status` | Status do scraping |
| GET | `/scraping/results` | Resultados do scraping |
| POST | `/scraping/start` | Iniciar scraping |
| POST | `/scraping/stop` | Parar scraping |
| GET | `/scraping/proxies` | EstatÃ­sticas dos proxies |
| POST | `/scraping/proxies` | Adicionar proxies |
| POST | `/scraping/proxies/validate` | Validar proxies |

## ğŸ—ï¸ Arquitetura

```
api/scraping/
â”œâ”€â”€ __init__.py           # Exporta scraping_router
â”œâ”€â”€ proxy_manager.py      # Gerenciamento de proxies
â”œâ”€â”€ distrowatch_scraper.py # LÃ³gica de scraping
â”œâ”€â”€ routes.py             # Endpoints FastAPI
â”œâ”€â”€ requirements.txt      # DependÃªncias
â””â”€â”€ README.md            # Esta documentaÃ§Ã£o
```

## ğŸ”§ ConfiguraÃ§Ã£o

### ProxyManager

```python
from api.scraping.proxy_manager import ProxyManager

# Criar gerenciador com proxies
proxy_manager = ProxyManager(
    proxies=[
        "http://proxy1.com:8080",
        "http://proxy2.com:8080"
    ],
    max_failures=3  # MÃ¡ximo de falhas antes de desativar
)

# Obter proxy aleatÃ³rio
proxy = proxy_manager.get_random_proxy()

# Reportar falha
proxy_manager.report_failure(proxy)

# EstatÃ­sticas
stats = proxy_manager.get_stats()
```

### DistroWatchScraper

```python
from api.scraping.distrowatch_scraper import DistroWatchScraper

# Criar scraper
scraper = DistroWatchScraper(proxy_manager)

# Scrape lista de distros
distros = scraper.scrape_distro_list()

# Scrape detalhes de uma distro
details = scraper.scrape_distro_details("https://distrowatch.com/table.php?distribution=ubuntu")

# Scrape completo (lista + detalhes)
all_distros = scraper.scrape_all(limit=10)
```

## âš ï¸ ConsideraÃ§Ãµes Importantes

### Proxies
- **Use proxies Ã©ticos e legais**
- Proxies gratuitos podem ser lentos ou instÃ¡veis
- Considere usar serviÃ§os de proxy pagos para melhor performance
- Respeite os termos de serviÃ§o do DistroWatch

### Rate Limiting
- O scraper jÃ¡ inclui delays aleatÃ³rios entre requisiÃ§Ãµes
- NÃ£o abuse do DistroWatch - eles fornecem dados gratuitamente
- Considere fazer scraping em horÃ¡rios de baixo trÃ¡fego

### Estrutura HTML
- A estrutura do DistroWatch pode mudar sem aviso
- Os seletores CSS/XPath podem precisar de ajustes
- Teste regularmente para garantir funcionamento

## ğŸ—‘ï¸ RemoÃ§Ã£o do MÃ³dulo

Para remover completamente o mÃ³dulo de scraping:

1. **Remover import** em `api/main.py`:
```python
# Remover esta linha:
from .scraping import scraping_router
```

2. **Remover registro** em `api/main.py`:
```python
# Remover esta linha:
app.include_router(scraping_router)
```

3. **Deletar pasta**:
```bash
rm -rf api/scraping/
```

Pronto! O mÃ³dulo estÃ¡ completamente removido sem afetar o resto da API.

## ğŸ“ Exemplo de Uso Completo

```python
import asyncio
from api.scraping.proxy_manager import ProxyManager
from api.scraping.distrowatch_scraper import DistroWatchScraper

async def main():
    # 1. Configurar proxies
    proxy_manager = ProxyManager([
        "http://proxy1.com:8080",
        "http://proxy2.com:8080"
    ])
    
    # 2. Criar scraper
    scraper = DistroWatchScraper(proxy_manager)
    
    # 3. Scrape completo (limitado a 5 distros)
    distros = scraper.scrape_all(limit=5)
    
    # 4. Processar resultados
    for distro in distros:
        print(f"Nome: {distro.get('name')}")
        print(f"URL: {distro.get('url')}")
        print(f"Baseado em: {distro.get('based_on')}")
        print("---")

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ› Troubleshooting

### "Nenhum proxy ativo disponÃ­vel"
- Valide seus proxies: `POST /scraping/proxies/validate`
- Adicione mais proxies: `POST /scraping/proxies`
- Verifique se os proxies estÃ£o online

### "IP ban do DistroWatch"
- Adicione mais proxies ao pool
- Aumente os delays entre requisiÃ§Ãµes
- Aguarde algumas horas antes de tentar novamente

### "Erro ao parsear HTML"
- A estrutura do DistroWatch pode ter mudado
- Verifique e ajuste os seletores em `distrowatch_scraper.py`
- Consulte o HTML atual do DistroWatch para referÃªncia

## ğŸ“š Recursos

- [DistroWatch](https://distrowatch.com)
- [BeautifulSoup Docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Requests Docs](https://requests.readthedocs.io/)
- [FastAPI Background Tasks](https://fastapi.tiangolo.com/tutorial/background-tasks/)

## ğŸ“„ LicenÃ§a

Este mÃ³dulo segue a mesma licenÃ§a do projeto principal (MIT).
